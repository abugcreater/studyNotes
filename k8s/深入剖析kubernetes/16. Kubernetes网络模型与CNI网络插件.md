# 16. Kubernetes网络模型与CNI网络插件

网络插件真正要做的事情，则是通过某种方法，**把不同宿主机上的特殊设备连通，从而达到容器跨主机通信的目的**.

Kubernetes 是通过一个叫作 CNI 的接口，维护了一个单独的网桥来代替 docker0。这个网桥的名字就叫作：CNI 网桥，它在宿主机上的设备名称默认是：cni0。

Kubernetes 环境中只是将docker0 网桥被替换成了 CNI 网桥而已，如下所示：

![k8s-16-2.png](../../img/k8s-16-2.png)

Kubernetes 为 Flannel 分配的子网范围是 10.244.0.0/16.这个参数可以在部署的时候指定,也可以在部署完成后修改kube-controller-manager 的配置文件来指定。

```sh
$ kubeadm init --pod-network-cidr=10.244.0.0/16
```

Kubernetes 之所以要设置这样一个与 docker0 网桥功能几乎一样的 CNI 网桥，主要原因包括两个方面：

- 一方面，Kubernetes 项目并没有使用 Docker 的网络模型（CNM），所以它并不希望、也不具备配置 docker0 网桥的能力；
- 另一方面，这还与 Kubernetes 如何配置 Pod，也就是 Infra 容器的 Network Namespace 密切相关。

CNI 的设计思想，就是：**Kubernetes 在启动 Infra 容器之后，就可以直接调用 CNI 网络插件，为这个 Infra 容器的 Network Namespace，配置符合预期的网络栈。**

> Network Namespace 的网络栈包括：网卡（Network Interface）、回环设备（Loopback Device）、路由表（Routing Table）和 iptables 规则

----

**这个网络栈的配置工作又是如何完成的**

我们可以在宿主机 /opt/cni/bin 目录下看到**CNI 插件所需的基础可执行文件**

这些 CNI 的基础可执行文件，按照功能可以分为三类：

**第一类，叫作 Main 插件，它是用来创建具体网络设备的二进制文件**。比如，bridge（网桥设备）、ipvlan、loopback（lo 设备）、macvlan、ptp（Veth Pair 设备），以及 vlan。

**第二类，叫作 IPAM（IP Address Management）插件，它是负责分配 IP 地址的二进制文件**。比如，dhcp，这个文件会向 DHCP 服务器发起请求；host-local，则会使用预先配置的 IP 地址段来进行分配。

**第三类，是由 CNI 社区维护的内置 CNI 插件**



如果想要实现一个给 Kubernetes 用的容器网络方案,需要做两部分工作.

**首先，实现这个网络方案本身**

**然后，实现该网络方案对应的 CNI 插件**,就是配置 Infra 容器里面的网络栈，并把它连接在 CNI 网桥上。

---

 **CNI 插件的工作原理**

Pod 初始化时会创建一个Infra容器,然后执行SetUpPod 方法,为CNI插件准备参数,然后调用CNI插件为Infra容器配置网络.

这里要调用的 CNI 插件，就是 /opt/cni/bin/flannel；而调用它所需要的参数，分为两部分。

**第一部分，是由 dockershim 设置的一组 CNI 环境变量。**

其中最重要的参数叫做CNI_COMMAND,只有ADD和DEL.表示将容器添加或移除CNI网络.

**这个 ADD 和 DEL 操作，就是 CNI 插件唯一需要实现的两个方法。**

CNI 的 ADD 操作需要的参数包括：容器里网卡的名字 eth0（CNI_IFNAME）、Pod 的 Network Namespace 文件的路径（CNI_NETNS）、容器的 ID（CNI_CONTAINERID）等。这些参数都属于上述环境变量里的内容

**第二部分，则是 dockershim 从 CNI 配置文件里加载到的、默认插件的配置信息。**

dockershim 会把这个配置参数( Network Configuration)以JSON格式,传递给Flannel CNI 插件。

> 如果配置有Delegate 字段,表示这个CNI插件不会自己做事,而是会调用Delegate 指定的某种CNI内置插件完成.

所以说，dockershim 对 Flannel CNI 插件的调用，其实就是走了个过场。Flannel CNI 插件唯一需要做的，就是对 dockershim 传来的 Network Configuration 进行补充。比如，将 Delegate 的 Type 字段设置为 bridge，将 Delegate 的 IPAM 字段设置为 host-local 等。

补充后的完整的 Delegate 字段如下所示：

```json
{
    "hairpinMode":true,
    "ipMasq":false,
    "ipam":{
        "routes":[
            {
                "dst":"10.244.0.0/16"
            }
        ],
        "subnet":"10.244.1.0/24",
        "type":"host-local"
    },
    "isDefaultGateway":true,
    "isGateway":true,
    "mtu":1410,
    "name":"cbr0",
    "type":"bridge"
}
```

获取完所有参数后,就需要进行**将容器加入到CNI网络里**,这一部分与容器的Network Namespace 密切相关

首先，CNI bridge 插件会在宿主机上检查 CNI 网桥是否存在。如果没有的话，那就创建它。这相当于在宿主机上执行：

```sh
# 在宿主机上
$ ip link add cni0 type bridge
$ ip link set cni0 up
```

接下来，CNI bridge 插件会通过 Infra 容器的 Network Namespace 文件，进入到这个 Network Namespace 里面，然后创建一对 Veth Pair 设备。然后将一端移动到宿主机.就相当于在容器中执行了以下命令:

```sh
# 在容器里
 
# 创建一对 Veth Pair 设备。其中一个叫作 eth0，另一个叫作 vethb4963f3
$ ip link add eth0 type veth peer name vethb4963f3
 
# 启动 eth0 设备
$ ip link set eth0 up 
 
# 将 Veth Pair 设备的另一端（也就是 vethb4963f3 设备）放到宿主机（也就是 Host Namespace）里
$ ip link set vethb4963f3 netns $HOST_NS
 
# 通过 Host Namespace，启动宿主机上的 vethb4963f3 设备
$ ip netns exec $HOST_NS ip link set vethb4963f3 up 
```

接下来，CNI bridge 插件就可以把 vethb4963f3 设备连接在 CNI 网桥上。这相当于在宿主机上执行：

```sh
# 在宿主机上
$ ip link set vethb4963f3 master cni0
```

> CNI bridge 插件还会为它设置**Hairpin Mode（发夹模式）**。这是因为，在默认情况下，网桥设备是不允许一个数据包从一个端口进来后，再从这个端口发出去的。但是，它允许你为这个端口开启 Hairpin Mode，从而取消这个限制。

接下来，CNI bridge 插件会调用 CNI ipam 插件，从 ipam.subnet 字段规定的网段里为容器分配一个可用的 IP 地址。然后，CNI bridge 插件就会把这个 IP 地址添加在容器的 eth0 网卡上，同时为容器设置默认路由。这相当于在容器里执行：

```sh
# 在容器里
$ ip addr add 10.244.0.2/24 dev eth0
$ ip route add default via 10.244.0.1 dev eth0
```

最后，CNI bridge 插件会为 CNI 网桥添加 IP 地址。这相当于在宿主机上执行：

```sh
# 在宿主机上
$ ip addr add 10.244.0.1/24 dev cni0
```

在执行完上述操作之后，CNI 插件会把容器的 IP 地址等信息返回给 dockershim，然后被 kubelet 添加到 Pod 的 Status 字段。




















































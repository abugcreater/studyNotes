# 关于缓存一致性协议

## 1. CPU中缓存结构

CPU 高速运转，但取数据的速度非常慢，严重浪费了 CPU 的性能。为了解决CPU和内存速度不适配,使用了空间缓冲概念,在CPU于主存间添加类多级缓存.

**什么是 CPU 多级缓存？**

![img](https://a.perfma.net/img/3971423)

简单来说就是基于 *时间 = 距离 / 速度* 这个公式，通过在 CPU 和内存之间设置多层缓存来减少取数据的距离，让 CPU 和内存的速度能够更好的适配。

因为缓存离 CPU 近，而且结构更加合理，CPU 取数据的速度就缩短了，从而提高了 CPU 的利用率

CPU 取数据和指令满足时间局部性和空间局部性，有了缓存之后，对同一数据进行多次操作时，中间过程可以用缓存暂存数据，进一步分摊*时间 = 距离 / 速度* 中的距离，更好地提高了 CPU 利用率

> 时间局部性：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问
>
> 空间局部性：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用

## 2. 缓存不一致的原因

多核CPU架构中,每个CPU都单独享有一组私有缓存.这样设计虽然能解决多处理器抢占缓存的问题,但是会导致数据一致性问题.

![img](https://a.perfma.net/img/3971452)

CPU0和CPU1同时对age+1操作时,由于CPU间无法感知其他CPU对该数据的处理导致最终结果与预期结果不一致.

> 没有缓存也会出现数据一致性问题，只是有缓存会变得尤其严重。

数据不一致的问题对于程序来说是致命的。所以需要有一种协议，能够让多组缓存看起来就像只有一组缓存那样。于是，缓存一致性协议就诞生了。

## 3. 缓存一致性协议

缓存一致性协议就是为了解决缓存一致性问题而诞生，它旨在通过维护多个缓存空间中*缓存行*的一致视图来管理数据一致性。

> 缓存行的概念:
>
> 缓存行(cache line)是缓存读取的最小单元,大小为2的整数幂个连续字节,一般为32-256字节,常见大小为64字节
>
> Linux 系统可以通过`cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size`命令查看缓存行大小。
>
> Mac 系统可以通过`sysctl hw.cachelinesize`查看缓存行的大小。

缓冲一致性协议主要实现机制由两种,分别是基于目录和总线嗅探

### 3.1 基于目录的缓存一致性协议

基本实现是用一个目录记录缓存行的使用情况,然后CPU要使用缓存行的时候,先通过目录获取此缓存行的使用情况,用这样的方式保证数据一致性.

根据目录的数据结构与优化方式,目录有以下6种格式:

1. 全位向量格式（Full bit vector format）
2. 粗位向量格式（Coarse bit vector format）
3. 稀疏目录格式（Sparse directory format）
4. 数字平衡二叉树格式（Number-balanced binary tree format）
5. 链式目录格式（Chained directory format）
6. 有限的指针格式（Limited pointer format）

全位向量格式就是用比特位(bit)去记录每个缓存行是否被某个CPU缓存.

![img](https://a.perfma.net/img/3971470)

目录方式相对于直接消息通信来说是比较耗时的，所以基于目录这种机制实现的缓存一致性协议延迟相对来说会偏高。但也有一个好处，第三方目录的存在让通信过程变得简单，通信对总线带宽的占用也会相对偏少.适用于CPU核心数量多的大型系统.

### 3.2 总线嗅探

小型系统更多的是用基于**总线嗅探**的缓存一致性协议。总线是CPU和内存地址和数据交互的桥梁,总线嗅探也就是监听着这座交互桥梁,及时的感知数据的更改.

![img](https://a.perfma.net/img/3971491)

当 CPU 修改私有缓存里面的数据时，会给总线发送一个事件消息，告诉总线上的其他监听者这个数据被修改了。

## 4.MESI

MESI 协议是一个基于失效的缓存一致性协议，是支持写回（write-back）缓存的最常用协议，也是现在一种使用最广泛的缓存一致性协议，它基于总线嗅探实现，用额外的两位给每个缓存行标记状态，并且维护状态的切换，达到缓存一致性的目的。

**MESI 状态**

1. M：**modified**，已修改。缓存行与主存的值不同。如果别的 CPU 内核要读主存这块数据，该缓存行必须回写到主存，状态变为共享状态（S）。
2. E：**exclusive**，独占的。缓存行只在当前缓存中，但和主存数据一致。当别的缓存读取它时，状态变为共享；当前写数据时，变为已修改状态（M）。
3. S：**shared**，共享的。缓存行也存在于其它缓存中且是干净的。缓存行可以在任意时刻抛弃。
4. I：**invalid**，无效的。缓存行是无效的。

**MESI 消息**

缓存行状态的切换依赖消息的传递,有一下几种消息

1. Read: 读取某个地址的数据。
2. Read Response: Read 消息的响应。
3. Invalidate: 请求其他 CPU invalid 地址对应的缓存行。
4. Invalidate Acknowledge: Invalidate 消息的响应。
5. Read Invalidate: Read + Invalidate 消息的组合消息。
6. Writeback: 该消息包含要回写到内存的地址和数据。

实现细节可以通过,[这个网站](https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm)具体实操.

## 5. Store Buffer

虽然CPU能通过发送 Read Invalidate 消息去读取对应的数据，并让其他的缓存副本失效。但是等待响应的过程对CPU来说太过漫长了.

*store buffer* 是CPU和缓存中的一块结构,他能减少CPU等待消息的时间.

![img](https://a.perfma.net/img/3972578)

CPU 在写操作时，可以不等待其他 CPU 响应消息就直接写到 store buffer，后续收到响应消息之后，再把 store buffer 里面的数据写入缓存行.

CPU在读操作时也会优先读取 store buffer中的数据.但是 store bufferD 引入并不能保证多CPU的全局顺序执行.

下面是这段代码在CPU操作中的演示:

```c
// CPU0 执行
void foo() { 
    a = 1;
    b = 1;
}

// CPU1 执行
void bar() {
    while(b == 0) continue;
    assert(a == 1);
}
```

![img](https://a.perfma.net/img/3972625)

1. CPU0 执行 a=1，因为 a 不在 CPU0 的缓存中，有 store buffer 的存在，直接写将 a=1 写到 store buffer，同时发送一个 read invalidate 消息。
2. CPU1 执行 while(b==1)，因为 b 不在 CPU1 的缓存中，所以 CPU1 发送一个 read 消息去读。
3. CPU0 收到 CPU1 的 read 消息，知道 CPU1 想要读 b，于是返回一个 read response 消息，同时将对应缓存行的状态改成 S。
4. CPU1 收到 read response 消息，知道 b=1，于是将 b=1 放到缓存，同时结束 while 循环。
5. CPU1 执行 assert(a==1)，从缓存中拿到 a=0，执行失败。

硬件设计师给开发者提供了**内存屏障（memory-barrier）**指令，我们只需要使用内存屏障将代码改造一下，在 a = 1 后面加上 **p_mb()，就能消除 store buffer 的引入带来的影响。

有两种方式能保证全局顺序一致性,**等 store buffer 生效**和**进 store buffer 排队**。

**等 store buffer 生效**

等 store buffer 生效就是内存屏障后续的写必须等待 store buffer 里面的值都收到了对应的响应消息，都被写到缓存行里面。

**进 store buffer 排队**

进 store buffer 排队就是内存屏障后续的写直接写到 store buffer 排队，等 store buffer 前面的写全部被写到缓存行



**等 store buffer 生效**是在 CPU 等，而**进 store buffer 排队**是进 store buffer 等。

所以，**进 store buffer 排队**也会相对高效一些，大多数的系统采用的也是这种方式。

## 6. Invalidate Queue

![img](https://a.perfma.net/img/3972675)

invalidate queue 的主要作用就是提高 invalidate 消息的响应速度。

有了 invalidate queue 之后，CPU 在收到 invalidate 消息时，可以先不讲对应的缓存行失效，而是将消息放入 invalidate queue，立即返回 Invalidate Acknowledge 消息，然后在要对外发送 invalidate 消息时，先检查 invalidate queue 中有无该缓存行的 Invalidate 消息，如果有的话这个时候才处理 Invalidate 消息.

在引入 invalidate queue 之后，全局顺序性又得不到保障了。解决这个问题的方法与store buffer相似,都是引入类内存屏障.

## 7. 内存屏障和 Lock 指令

内存屏障有两个作用，处理 store buffer 和 invalidate queue，保持全局顺序性。

但很多情况下，只需要处理 store buffer 和 invalidate queue 中的其中一个即可，所以很多系统将内存屏障细分成了读屏障（read memory barrier）和写屏障（write memory barrier）

读屏障用于处理 invalidate queue，写屏障用于处理 store buffer。

- 读屏障：lfence
- 写屏障：sfence
- 读写屏障：mfence

**Lock指令**

我认为是没有什么关系的。

只不过 lock 前缀指令一部分功能能达到内存屏障的效果罢了.

这一点在《IA-32 架构软件开发人员手册》上也能找到对应的描述。

手册上给 lock 前缀指令的定义是总线锁，也就是 lock 前缀指令是通过锁住总线保证可见性和禁止指令重排序的。

虽然“总线锁”的说法过于老旧了，现在的系统更多的是“锁缓存行”。但我想表达的是，lock 前缀指令的核心思想还是“锁”，这和内存屏障有着本质的区别。

## 8. 总结

1. 因为内存的速度和 CPU 匹配不上，所以在内存和 CPU 之间加了多级缓存。
2. 单核 CPU 独享不会出现数据不一致的问题，但是多核情况下会有缓存一致性问题。
3. 缓存一致性协议就是为了解决多组缓存导致的缓存一致性问题。
4. 缓存一致性协议有两种实现方式，一个是基于目录的，一个是基于总线嗅探的。
5. 基于目录的方式延迟高，但是占用总线流量小，适合 CPU 核数多的系统。
6. 基于总线嗅探的方式延迟低，但是占用总线流量大，适合 CPU 核数小的系统。
7. 常见的 MESI 协议就是基于总线嗅探实现的。
8. MESI 解决了缓存一致性问题，但是还是不能将 CPU 性能压榨到极致。
9. 为了进一步压榨 CPU，所以引入了 store buffer 和 invalidate queue。
10. store buffer 和 invalidate queue 的引入导致不满足全局有序，所以需要有写屏障和读屏障。
11. X86 架构下的读屏障指令是 lfenc，写屏障指令是 sfence，读写屏障指令是 mfence。
12. lock 前缀指令直接锁缓存行，也能达到内存屏障的效果。
13. x86 架构下，volatile 的底层实现就是 lock 前缀指令。
14. JMM 是一个模型，是一个便于 Java 开发人员开发的抽象模型。
15. 缓存性一致性协议是为了解决 CPU 多核系统下的数据一致性问题，是一个客观存在的东西，不需要去触发。
16. **JMM 和缓存一致性协议没有一毛钱关系。**
17. **JMM 和 MESI 没有一毛钱关系。**



参考:[关于缓存一致性协议、MESI、StoreBuffer、InvalidateQueue、内存屏障、Lock指令和JMM的那点事](https://heapdump.cn/article/3971578?from=pc)

[MESI原理演示](https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm)